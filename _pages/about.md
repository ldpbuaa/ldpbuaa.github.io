---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
Dongping Liao is now a postdoc researcher at University of Macau. In 2024, he received his Ph.D. degree in computer science from the Faculty of Science and Technology, University of Macau, Taipa, China.
His current research interests include distributed optimization, class imbalance learning and multi-modal models.


# ğŸ”¥ News
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ One co-authored paper is accepted by CVPR 2025. 
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2025. 
- *2023.12*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by AAAI 2024. 
- *2023.02*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by CVPR 2023. 

# ğŸ“ Publications 

**2025**


**Dongping Liao**, Xitong Gao, Yabo Xu, Chengzhong Xu,  "Progressive Distribution Matching for Federated Semi-supervised Learning" (AAAI 2025, CCF A)

**2024**

**Dongping Liao**, Xitong Gao, Chengzhong Xu, "Impartial Adversarial Distillation: Addressing Biased Data-free Knowledge Distillation via Adaptive Constrained Optimization" (AAAI 2024, CCF A)

**2023**


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/paper-flado-overview.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Adaptive Channel Sparsity for Federated Learning under System Heterogeneity](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Dongping Liao**, Xitong Gao, Yiren Zhao, Chengzhong Xu

- We figure out the coupling effect of data and system heterogeneity under federated training, namely, the gradient deviation. We propose Flado, which is equipped with adaptive channel sparsity layer to address the conflicting gradient updates among client models. 
</div>
</div>

# ğŸ– Honors and Awards
- *2018.06* The second place for Gomoku AI Competition, DeepGlint
- *2019.03* Outstanding academic publication award for master student, Beihang University. 
- *2019.06* Macau Ph.D. scholarship (1,000,000 MOP). 
